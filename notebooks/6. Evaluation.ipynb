{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animal-change",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To inspect the evaulation results, we first need to load all files containing results from the output evaluation directory.\\\n",
    "We load the results as a pandas data frame and clean it. In the second next code block at the end, the resulting data frame can be display by including the commented out statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "innocent-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from ipywidgets import widgets, interact, interact_manual, Layout, Button, Box\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from r2pa.api import routines\n",
    "from april.fs import EVALUATION_DIR\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-steps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1606f0035e9f40ec936f1ca70ee8ba9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_dict_from_lists(key_list, value_list):\n",
    "    dictionary = {}\n",
    "    for i, key in enumerate(key_list):\n",
    "        dictionary[key] = value_list[i]\n",
    "    return dictionary\n",
    "\n",
    "def create_combined_columns(df, columns):\n",
    "    df[' '.join(columns)] = df[columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "    \n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# load all csv files and convert to data frame\n",
    "all_csvs = [file for file in os.listdir(EVALUATION_DIR) if file[-4:] == '.csv']\n",
    "\n",
    "all_dfs = []\n",
    "for file in all_csvs:\n",
    "    file_df = pd.read_csv(EVALUATION_DIR / file)\n",
    "    all_dfs.append(file_df)\n",
    "    \n",
    "df = pd.concat(all_dfs)\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# convert to correct data types\n",
    "non_numeric_columns = [\"dataset\", \"next event predictor\", \"use cache\", 'group attribute nodes']\n",
    "for column in df.columns:\n",
    "    if column not in non_numeric_columns:\n",
    "        df[column] = pd.to_numeric(df[column])\n",
    "\n",
    "# rename columns\n",
    "identifiers_columns = ['dataset', 'next event predictor', 'next event threshold']\n",
    "identifiers_new_columns = ['dataset', 'nep', 'threshold']\n",
    "\n",
    "df.rename(columns=create_dict_from_lists(identifiers_columns, identifiers_new_columns), inplace=True)\n",
    "\n",
    "# add new columns\n",
    "df['total case generation time (seconds)'] = df['case generation time'] + df['cache generation time']\n",
    "df['total time per case (seconds)'] = df['total case generation time (seconds)'] / df['number of model cases']\n",
    "df['cases to graph per case (seconds)'] = df['cases to graph conversion time'] / df['number of model cases']\n",
    "\n",
    "# create combined columns and set index\n",
    "create_combined_columns(df, ['dataset', 'nep', 'threshold'])\n",
    "\n",
    "create_combined_columns(df, ['nep', 'threshold'])\n",
    "identifiers_new_columns.append('nep threshold')\n",
    "\n",
    "create_combined_columns(df, ['dataset', 'nep'])\n",
    "identifiers_new_columns.append('dataset nep')\n",
    "\n",
    "create_combined_columns(df, ['nep', 'use cache'])\n",
    "identifiers_new_columns.append('nep use cache')\n",
    "\n",
    "df = df.set_index('dataset nep threshold')\n",
    "\n",
    "# display data frame\n",
    "with output:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "        display(df)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-pencil",
   "metadata": {},
   "source": [
    "## Discovery\n",
    "\n",
    "After loading the data frame, we can start with the evaluation regarding process discovery evaluation metrics. We select the respective columns and rename them. \\\n",
    "We then plot results for the metrics F1 measure, precision, fitness,..\n",
    "\n",
    "Note that the generalization metric is only calculated when using a cache in the case generation.\n",
    "When the cache is not used, the metric is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sublime-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9785470023cc47c5913e29cb2c92ea69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_output = widgets.Output()\n",
    "\n",
    "discovery_metrics_columns = ['precision', 'precision average distance', 'fitness', 'fitness average distance', 'f1 measure', 'number of nodes model graph', 'percentage of uncached cases only ground truth cases']\n",
    "discovery_metrics_new_columns = ['P', 'PAD', 'F', 'FAD', 'F1', '#N', 'G']\n",
    "\n",
    "df_discovery = df[identifiers_new_columns + discovery_metrics_columns]\n",
    "df_discovery.rename(columns=create_dict_from_lists(discovery_metrics_columns, discovery_metrics_new_columns), inplace=True)\n",
    "\n",
    "with discovery_output:\n",
    "    # f1 measure\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='F1', hue='nep', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best F1 Measure Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('F1 Measure')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # precision\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='P', hue='nep', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best Precision Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # fitness\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='F', hue='nep', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best Fitness Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # generalization\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='G', hue='nep', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best Generalization Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Generalization')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_discovery)\n",
    "        \n",
    "display(discovery_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-waters",
   "metadata": {},
   "source": [
    "To inspect the result for a certain event log, set the variable in the next code block. The previous code block must be run before this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precious-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d8b96f9da746c1bcaca02d95b87099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_dataset_output = widgets.Output()\n",
    "\n",
    "dataset_selection = 'papermanual-0.3-1'\n",
    "df_discovery_dataset = df_discovery.loc[df_discovery['dataset'] == dataset_selection]\n",
    "\n",
    "with discovery_dataset_output:\n",
    "    # f1 measure\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='F1', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best F1 Measure Scores For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('F1 Measure')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # precision\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='P', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best Precision Scores For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # fitness\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='F', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title='NEP')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best Fitness Scores For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # generalization\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='G', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best Generalization Scores For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('Generalization')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "display(discovery_dataset_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-slovak",
   "metadata": {},
   "source": [
    "## Likelihoods\n",
    "Next, we take a look at how accurate the learned likelihoods are. We inspect the average deviation from the correct likelihoods for an event and for cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "green-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6969424f4b2943b0a95268de9aa8d0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "likelihood_output = widgets.Output()\n",
    "\n",
    "likelihood_metrics_columns = ['absolute likelihood difference per case and attribute', 'mean squared error likelihoods', 'likelihood difference per case', 'normalized likelihood difference per case', ]\n",
    "likelihood_metrics_new_columns = ['ALDE', 'MSE', 'ALDC', 'NALDC']\n",
    "\n",
    "df_likelihoods = df[identifiers_new_columns + likelihood_metrics_columns]\n",
    "df_likelihoods.rename(columns=create_dict_from_lists(likelihood_metrics_columns, likelihood_metrics_new_columns), inplace=True)\n",
    "\n",
    "with likelihood_output:\n",
    "    # ALDE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='ALDE', hue='nep', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title('Best ALDE Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('ALDE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # MSE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='MSE', hue='nep', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title('Best MSE Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # ALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='ALDC', hue='nep', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title('Best ALDC Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('ALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # NALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='NALDC', hue='nep', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title('Best NALDC Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('NALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_likelihoods)\n",
    "    \n",
    "display(likelihood_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-trail",
   "metadata": {},
   "source": [
    "To inspect the result for a certain event log, set the variable in the next code block. The previous code block must be run before this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rising-tobacco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0c1f2f2ce545a7ae2462b4119f7031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_likelihoods_output = widgets.Output()\n",
    "\n",
    "dataset_selection = 'papermanual-0.3-1'\n",
    "df_likelihoods_dataset = df_likelihoods.loc[df_likelihoods['dataset'] == dataset_selection]\n",
    "\n",
    "with discovery_likelihoods_output:\n",
    "    # ALDE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='ALDE', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title(f'Best ALDE For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('ALDE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # MSE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='MSE', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title(f'Best MSE For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # ALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='ALDC', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title(f'Best ALDC For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('ALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # NALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='nep', y='NALDC', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title(f'Best NALDC For {dataset_selection}')\n",
    "    plt.xlabel('NEP')\n",
    "    plt.ylabel('NALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "display(discovery_likelihoods_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-performer",
   "metadata": {},
   "source": [
    "## Timings\n",
    "\n",
    "Finally, we can inspect the run time required to discover the process models.\n",
    "Due to possibly generating different numbers of cases,\\\n",
    "in which the next event threshold plays a large role, we mostly regard the time taken per case generated.\\\n",
    "We also plot the differences in run time when using a cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "embedded-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c90fa30df44dbc959b615895ea3c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timings_output = widgets.Output()\n",
    "\n",
    "timings_metrics_columns = ['use cache', 'total case generation time (seconds)', 'total time per case (seconds)', 'cases to graph conversion time', 'cache generation time', \n",
    "                           'case generation time', 'cases to graph per case (seconds)']\n",
    "timings_metrics_new_columns = ['use cache', 'total case generation', 'total time per case', 'graph creation', 'cache generation', 'case generation', 'graph creation per case']\n",
    "\n",
    "df_timings = df[identifiers_new_columns + timings_metrics_columns]\n",
    "df_timings.rename(columns=create_dict_from_lists(timings_metrics_columns, timings_metrics_new_columns), inplace=True)\n",
    "\n",
    "with timings_output:\n",
    "    # total case generation\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total case generation', hue='nep', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title('Case Generation Time Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total time per case \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total time per case', hue='nep', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title('Case Generation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time Per Case (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total time per case \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='graph creation per case', hue='nep', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP\")\n",
    "    plt.title('Graph Creation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time Per Case (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total case generation use cache\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total case generation', hue='nep use cache', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP, Use Cache\")\n",
    "    plt.title('Case Generation Time Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total case generation per case use cache\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total time per case', hue='nep use cache', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"NEP, Use Cache\")\n",
    "    plt.title('Case Generation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_timings)\n",
    "        \n",
    "display(timings_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-thumb",
   "metadata": {},
   "source": [
    "Next, we plot the case generation time per case vs. the F1 measure. Therefore we can see which model performs best when considering run time.\\\n",
    "\n",
    "Note that the limits of the plot might need to be adjusted for other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brief-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd70106758142598fbdb8108017076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_output = widgets.Output()\n",
    "\n",
    "df_scatter = df[identifiers_new_columns + discovery_metrics_columns + timings_metrics_columns]\n",
    "df_scatter.rename(columns=create_dict_from_lists(discovery_metrics_columns, discovery_metrics_new_columns), inplace=True)\n",
    "df_scatter.rename(columns=create_dict_from_lists(timings_metrics_columns, timings_metrics_new_columns), inplace=True)\n",
    "\n",
    "with scatter_output:\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.scatterplot(data=df_scatter, x='total time per case', y='F1', hue='nep', style='dataset')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title('Case Generation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Generation Time Per Case (Seconds)')\n",
    "    plt.ylabel('F1-Measure')\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlim(0, 0.2) # TODO:\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_scatter)\n",
    "    \n",
    "display(scatter_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-advisory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
