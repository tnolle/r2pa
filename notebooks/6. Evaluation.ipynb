{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "royal-experience",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To inspect the evaulation results, we first need to load all files containing results from the output evaluation directory.\\\n",
    "We load the results as a pandas data frame and clean it. In the second next code block at the end, the resulting data frame can be display by including the commented out statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesbian-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from ipywidgets import widgets, interact, interact_manual, Layout, Button, Box\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from r2pa.api import routines\n",
    "from april.fs import EVALUATION_DIR\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "given-cornwall",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"number of model cases\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"number of model cases\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a1761d5c9658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnon_numeric_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# rename columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             values = lib.maybe_convert_numeric(\n\u001b[1;32m--> 150\u001b[1;33m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m             )\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"number of model cases\" at position 0"
     ]
    }
   ],
   "source": [
    "def create_dict_from_lists(key_list, value_list):\n",
    "    dictionary = {}\n",
    "    for i, key in enumerate(key_list):\n",
    "        dictionary[key] = value_list[i]\n",
    "    return dictionary\n",
    "\n",
    "def create_combined_columns(df, columns):\n",
    "    df[' '.join(columns)] = df[columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "    \n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# load all csv files and convert to data frame\n",
    "all_csvs = [file for file in os.listdir(EVALUATION_DIR) if file[-4:] == '.csv']\n",
    "\n",
    "all_dfs = []\n",
    "for file in all_csvs:\n",
    "    file_df = pd.read_csv(EVALUATION_DIR / file, index_col=0, header=None).transpose()\n",
    "    \n",
    "    # get BINet version from file name\n",
    "    model = file.split('_')[1]\n",
    "    file_df.at[1, 'model'] = model\n",
    "    \n",
    "    all_dfs.append(file_df)\n",
    "    \n",
    "df = pd.concat(all_dfs)\n",
    "\n",
    "# convert to correct data types\n",
    "non_numeric_columns = [\"dataset\", \"model\", \"use cache\", 'group attribute nodes']\n",
    "for column in df.columns:\n",
    "    if column not in non_numeric_columns:\n",
    "        df[column] = pd.to_numeric(df[column])\n",
    "\n",
    "# rename columns\n",
    "identifiers_columns = ['dataset', 'model', 'next event threshold']\n",
    "identifiers_new_columns = ['dataset', 'model', 'threshold']\n",
    "\n",
    "df.rename(columns=create_dict_from_lists(identifiers_columns, identifiers_new_columns), inplace=True)\n",
    "\n",
    "# add new columns\n",
    "df['total case generation time (seconds)'] = df['generate walks time (seconds)'] + df['cache generation time (seconds)']\n",
    "df['total time per case (seconds)'] = df['total case generation time (seconds)'] / df['number of model walks']\n",
    "df['cases to graph per case (seconds)'] = df['convert walks to graph time (seconds)'] / df['number of model walks']\n",
    "\n",
    "# create combined columns and set index\n",
    "create_combined_columns(df, ['dataset', 'model', 'threshold'])\n",
    "\n",
    "create_combined_columns(df, ['model', 'threshold'])\n",
    "identifiers_new_columns.append('model threshold')\n",
    "\n",
    "create_combined_columns(df, ['dataset', 'model'])\n",
    "identifiers_new_columns.append('dataset model')\n",
    "\n",
    "create_combined_columns(df, ['model', 'use cache'])\n",
    "identifiers_new_columns.append('model use cache')\n",
    "\n",
    "df = df.set_index('dataset model threshold')\n",
    "\n",
    "# display data frame\n",
    "with output:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "        display(df)\n",
    "\n",
    "# display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-database",
   "metadata": {},
   "source": [
    "## Discovery\n",
    "\n",
    "After loading the data frame, we can start with the evaluation regarding process discovery evaluation metrics. We select the respective columns and rename them. \\\n",
    "We then plot results for the metrics F1 measure, precision, fitness,..\n",
    "\n",
    "Note that the generalization metric is only calculated when using a cache in the case generation.\n",
    "When the cache is not used, the metric is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-dating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acbea297e7c4a178d523ec7ecf886c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_output = widgets.Output()\n",
    "\n",
    "discovery_metrics_columns = ['precision', 'precision average distance', 'fitness', 'fitness average distance', 'f1 measure', 'number of nodes model graph', 'percentage of uncached walks only ground truth walks']\n",
    "discovery_metrics_new_columns = ['P', 'PAD', 'F', 'FAD', 'F1', '#N', 'G']\n",
    "\n",
    "df_discovery = df[identifiers_new_columns + discovery_metrics_columns]\n",
    "df_discovery.rename(columns=create_dict_from_lists(discovery_metrics_columns, discovery_metrics_new_columns), inplace=True)\n",
    "\n",
    "with discovery_output:\n",
    "    # f1 measure\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='F1', hue='model', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best F1 Measure Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('F1 Measure')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # precision\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='P', hue='model', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best Precision Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # fitness\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='F', hue='model', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best Fitness Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # generalization\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='G', hue='model', estimator=max, ci=None, data=df_discovery)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Best Generalization Scores Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Generalization')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_discovery)\n",
    "        \n",
    "display(discovery_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-sequence",
   "metadata": {},
   "source": [
    "To inspect the result for a certain event log, set the variable in the next code block. The previous code block must be run before this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separate-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee9c19077cf4ee59d63fd0a2df7bbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_dataset_output = widgets.Output()\n",
    "\n",
    "dataset_selection = 'paper-0.3-1'\n",
    "df_discovery_dataset = df_discovery.loc[df_discovery['dataset'] == dataset_selection]\n",
    "\n",
    "with discovery_dataset_output:\n",
    "    # f1 measure\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='F1', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best F1 Measure Scores For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('F1 Measure')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # precision\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='P', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best Precision Scores For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # fitness\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='F', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best Fitness Scores For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # generalization\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='G', hue='threshold', estimator=max, ci=None, data=df_discovery_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Best Generalization Scores For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Generalization')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "display(discovery_dataset_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-receptor",
   "metadata": {},
   "source": [
    "## Likelihoods\n",
    "Next, we take a look at how accurate the learned likelihoods are. We inspect the average deviation from the correct likelihoods for an event and for cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prompt-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c6c4f7a3e9462abaf9b77c4f2d6fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "likelihood_output = widgets.Output()\n",
    "\n",
    "likelihood_metrics_columns = ['absolute likelihood difference per walk and attribute', 'mean squared error likelihoods', 'likelihood difference per walk', 'normalized likelihood difference per walk', ]\n",
    "likelihood_metrics_new_columns = ['ALDE', 'MSE', 'ALDC', 'NALDC']\n",
    "\n",
    "df_likelihoods = df[identifiers_new_columns + likelihood_metrics_columns]\n",
    "df_likelihoods.rename(columns=create_dict_from_lists(likelihood_metrics_columns, likelihood_metrics_new_columns), inplace=True)\n",
    "\n",
    "with likelihood_output:\n",
    "    # ALDE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='ALDE', hue='model', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title('Best ALDE Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('ALDE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # MSE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='MSE', hue='model', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title('Best MSE Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # ALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='ALDC', hue='model', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title('Best ALDC Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('ALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # NALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='NALDC', hue='model', estimator=min, ci=None, data=df_likelihoods)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title('Best NALDC Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('NALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_likelihoods)\n",
    "    \n",
    "display(likelihood_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-enclosure",
   "metadata": {},
   "source": [
    "To inspect the result for a certain event log, set the variable in the next code block. The previous code block must be run before this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comparative-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9e24074520493f900f700d6b88c4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_likelihoods_output = widgets.Output()\n",
    "\n",
    "dataset_selection = 'paper-0.3-1'\n",
    "df_likelihoods_dataset = df_likelihoods.loc[df_likelihoods['dataset'] == dataset_selection]\n",
    "\n",
    "with discovery_likelihoods_output:\n",
    "    # ALDE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='ALDE', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title(f'Best ALDE For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('ALDE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # MSE\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='MSE', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title(f'Best MSE For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # ALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='ALDC', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title(f'Best ALDC For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('ALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # NALDC\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='model', y='NALDC', hue='threshold', estimator=max, ci=None, data=df_likelihoods_dataset)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title(f'Best NALDC For {dataset_selection}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('NALDC')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "display(discovery_likelihoods_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-notebook",
   "metadata": {},
   "source": [
    "## Timings\n",
    "\n",
    "Finally, we can inspect the run time required to discover the process models.\n",
    "Due to possibly generating different numbers of cases,\\\n",
    "in which the next event threshold plays a large role, we mostly regard the time taken per case generated.\\\n",
    "We also plot the differences in run time when using a cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "municipal-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcec3ae1530411189840d85c4b365ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timings_output = widgets.Output()\n",
    "\n",
    "timings_metrics_columns = ['use cache', 'total case generation time (seconds)', 'total time per case (seconds)', 'graph generation time (seconds)', 'cache generation time (seconds)', \n",
    "                           'generate walks time (seconds)', 'convert walks to graph time (seconds)', 'cases to graph per case (seconds)']\n",
    "timings_metrics_new_columns = ['use cache', 'total case generation', 'total time per case', 'graph creation', 'cache generation', 'case generation', 'graph creation', 'graph creation per case']\n",
    "\n",
    "df_timings = df[identifiers_new_columns + timings_metrics_columns]\n",
    "df_timings.rename(columns=create_dict_from_lists(timings_metrics_columns, timings_metrics_new_columns), inplace=True)\n",
    "\n",
    "with timings_output:\n",
    "    # total case generation\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total case generation', hue='model', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title('Case Generation Time Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total time per case \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total time per case', hue='model', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title('Case Generation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time Per Case (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total time per case \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='graph creation per case', hue='model', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model\")\n",
    "    plt.title('Graph Creation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time Per Case (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total case generation use cache\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total case generation', hue='model use cache', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model, Use Cache\")\n",
    "    plt.title('Case Generation Time Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # total case generation per case use cache\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(x='dataset', y='total time per case', hue='model use cache', data=df_timings)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=\"Model, Use Cache\")\n",
    "    plt.title('Case Generation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Event Log')\n",
    "    plt.ylabel('Time (Seconds)')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_timings)\n",
    "        \n",
    "display(timings_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-liability",
   "metadata": {},
   "source": [
    "Next, we plot the case generation time per case vs. the F1 measure. Therefore we can see which model performs best when considering run time.\\\n",
    "\n",
    "Note that the limits of the plot might need to be adjusted for other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "smaller-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanni\\Anaconda3\\envs\\ad\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a687f5dc6fb84980a19902aad0618f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_output = widgets.Output()\n",
    "\n",
    "df_scatter = df[identifiers_new_columns + discovery_metrics_columns + timings_metrics_columns]\n",
    "df_scatter.rename(columns=create_dict_from_lists(discovery_metrics_columns, discovery_metrics_new_columns), inplace=True)\n",
    "df_scatter.rename(columns=create_dict_from_lists(timings_metrics_columns, timings_metrics_new_columns), inplace=True)\n",
    "\n",
    "with scatter_output:\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.scatterplot(data=df_scatter, x='total time per case', y='F1', hue='model', style='dataset')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title('Case Generation Time Per Case Across Event Logs')\n",
    "    plt.xlabel('Generation Time Per Case (Seconds)')\n",
    "    plt.ylabel('F1-Measure')\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlim(0, 0.2) # TODO:\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # display(df_scatter)\n",
    "    \n",
    "display(scatter_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-dinner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
